{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O-u9pPJzRQ6"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mostafaabla/garbage-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIygtaIuzmjm",
        "outputId": "367ed481-c8ac-4fa0-ca5e-d2a21d421b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading garbage-classification.zip to /content\n",
            " 91% 218M/239M [00:01<00:00, 155MB/s]\n",
            "100% 239M/239M [00:01<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/garbage-classification.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "_fLZDw0Fzo7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "5MGBnRVKzs-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Generators\n",
        "gen_train = ImageDataGenerator(rescale = 1/255, shear_range = 0.3, zoom_range = 0.3,\n",
        "                              horizontal_flip=True,validation_split = 0.2)\n",
        "\n",
        "train_data = gen_train.flow_from_directory(\"/content/garbage_classification\",\n",
        "                                           target_size = (256, 256), batch_size = 32, class_mode=\"categorical\",subset = \"training\")\n",
        "\n",
        "\n",
        "\n",
        "val_data = gen_train.flow_from_directory(\"/content/garbage_classification\",\n",
        "                                           target_size = (256, 256), batch_size = 32, class_mode=\"categorical\",subset = \"validation\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6R_L0aMzzIK",
        "outputId": "9b955613-90dc-4260-8c40-c2a651713929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12415 images belonging to 12 classes.\n",
            "Found 3100 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "conv_base = VGG16(weights = 'imagenet',include_top = False,input_shape = (256,256,3))"
      ],
      "metadata": {
        "id": "OIOyDKQcz5RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(52,activation='relu'))\n",
        "model.add(Dense(12,activation='softmax'))"
      ],
      "metadata": {
        "id": "lMoXnvtQz_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DedK3CSS0ESR",
        "outputId": "d4f46e07-5646-4180-aa80-cf532b7a977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 52)                1703988   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                636       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16419312 (62.63 MB)\n",
            "Trainable params: 1704624 (6.50 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =[\"accuracy\"])"
      ],
      "metadata": {
        "id": "k4cPviJw0GQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.fit(train_data,epochs = 10,steps_per_epoch=len(train_data),validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzVuHpyY0KZi",
        "outputId": "ed0557c0-8632-4305-85a6-5398d6b6b121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 10/388 [..............................] - ETA: 2:38:24 - loss: 2.7585 - accuracy: 0.3562"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model.save(\"network.h5\")"
      ],
      "metadata": {
        "id": "9pTy6WOP0M1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(\"network.h5\")"
      ],
      "metadata": {
        "id": "h9vIhtUE0QIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lbUCKw0P0TK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "output_class = [\"battery\", \"biological\", \"brown-glass\", \"cardboard\", \"clothes\", \"green-glass\", \"metal\", \"paper\", \"plastic\",\"shoes\",\"trash\",\"white-glass\"]\n",
        "def waste_prediction(new_image):\n",
        "  t_img = image.load_img(new_image, target_size = (256,256))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(t_img)\n",
        "  plt.show()\n",
        "\n",
        "  t_img = image.img_to_array(t_img)/255\n",
        "  t_img = np.expand_dims(t_img, axis=0)\n",
        "\n",
        "  predicted_array = model.predict(t_img)\n",
        "  predicted_value = output_class[np.argmax(predicted_array)]\n",
        "  predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "\n",
        "  print(\"Your waste material is \", predicted_value, \" with \", predicted_accuracy, \" % accuracy\")"
      ],
      "metadata": {
        "id": "o4AqC_lt0Vxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waste_prediction(\"/content/battery.jpg\")"
      ],
      "metadata": {
        "id": "YGXp62tT0Y4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PnCZQUC0kWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}